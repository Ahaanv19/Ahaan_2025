{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: \"Computer Bias\"\n",
    "type: ccc\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 1\n",
    "\n",
    "Disney Plus because, it recomends many movie and shows based on stuff you've watched before. It affects the user because it influences the descions someone might make when choosing a show to watch. The recomendations are based on shows you've seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 2\n",
    "A time technology didn't work well for me was when I was trying to work on an online course but the program became a very glitchy, and the videos were distorted. It caused huge amounts of frustation, and really slowed down the amount of work I was able to do. It made me feel annoyed, and a way to fix this could be daily server checking on the online course program, to avoid these glitches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 3\n",
    "\n",
    "Bias in a fitness tracking app can be created if recommendations and performance evaluations are based on data that favor one party over another. It may not provide personalized feedback rather feedback that looks better for the company, and look bad to you so you would be more inclined to use their services to help improve their perfomance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Hack #1\n",
    "\n",
    "Tool: YouTube\n",
    "\n",
    "Identify Potential Bias: YouTube's recommendation algorithm is likely to create biast results by regularly showing similar content to what has been previously watched, and this may limit the varity of content a user watches. It could also favor popular creators, making them more popular, creating a bias.\n",
    "\n",
    "Analyzing the Cause: The cause of this bias is an engagement- and watch time-favoring algorithm that which encourages user preferences at the expense of promoting content diversity. The issue can also be caused by a shortage of diverse training data.\n",
    "\n",
    "Proposed Solution: YouTube can deploy diversity-conscious recommendations, user-chosen content filters, and greater accessibility features to offer a balanced exposure to different perspectives.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
